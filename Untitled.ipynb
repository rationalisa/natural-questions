{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2c08c739bd416ba420724d0eb678c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=634.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2412e1edbf0043e6962a8c0e4361124f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6ac078dbb246a5b4ab29911fd2956a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67869e83a6c445228f5ab3771f5a3d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3747814047894c728f6eff136cedfed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1334424802.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,EvalPrediction, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "#model = 'bert-base-uncased'\n",
    "model_pretrain = \"bert-large-cased-whole-word-masking-finetuned-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_pretrain,\n",
    "    use_fast=True,\n",
    "    revision='main',\n",
    ")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_pretrain, position_embedding_type=\"relative_key_query\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad and are newly initialized: ['bert.encoder.layer.0.attention.self.distance_embedding.weight', 'bert.encoder.layer.1.attention.self.distance_embedding.weight', 'bert.encoder.layer.2.attention.self.distance_embedding.weight', 'bert.encoder.layer.3.attention.self.distance_embedding.weight', 'bert.encoder.layer.4.attention.self.distance_embedding.weight', 'bert.encoder.layer.5.attention.self.distance_embedding.weight', 'bert.encoder.layer.6.attention.self.distance_embedding.weight', 'bert.encoder.layer.7.attention.self.distance_embedding.weight', 'bert.encoder.layer.8.attention.self.distance_embedding.weight', 'bert.encoder.layer.9.attention.self.distance_embedding.weight', 'bert.encoder.layer.10.attention.self.distance_embedding.weight', 'bert.encoder.layer.11.attention.self.distance_embedding.weight', 'bert.encoder.layer.12.attention.self.distance_embedding.weight', 'bert.encoder.layer.13.attention.self.distance_embedding.weight', 'bert.encoder.layer.14.attention.self.distance_embedding.weight', 'bert.encoder.layer.15.attention.self.distance_embedding.weight', 'bert.encoder.layer.16.attention.self.distance_embedding.weight', 'bert.encoder.layer.17.attention.self.distance_embedding.weight', 'bert.encoder.layer.18.attention.self.distance_embedding.weight', 'bert.encoder.layer.19.attention.self.distance_embedding.weight', 'bert.encoder.layer.20.attention.self.distance_embedding.weight', 'bert.encoder.layer.21.attention.self.distance_embedding.weight', 'bert.encoder.layer.22.attention.self.distance_embedding.weight', 'bert.encoder.layer.23.attention.self.distance_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 1024)\n",
      "    (token_type_embeddings): Embedding(2, 1024)\n",
      "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (12): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (13): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (14): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (15): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (16): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (17): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (18): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (19): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (20): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (21): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (22): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (23): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (distance_embedding): Embedding(1023, 64)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_pretrain, position_embedding_type=\"relative_key_query\"\n",
    ")\n",
    "print(model.base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/0fd9e01360d229a22adfe0ab7e2dd2adc6e2b3d6d3db03636a51235947d4c6e9)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,load_metric\n",
    "dataset_name = 'squad'\n",
    "datasets = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = True\n",
    "question_column_name = \"question\" \n",
    "context_column_name = \"context\"\n",
    "max_seq_length=384\n",
    "stride = 128\n",
    "batch_size=1\n",
    "answer_column_name = \"answers\" \n",
    "dir_name = 'squad'\n",
    "# Training preprocessing\n",
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[question_column_name if pad_on_right else context_column_name],\n",
    "        examples[context_column_name if pad_on_right else question_column_name],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[answer_column_name][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "def prepare_validation_features(examples):\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[question_column_name if pad_on_right else context_column_name],\n",
    "        examples[context_column_name if pad_on_right else question_column_name],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # For evaluation, we will need to convert our predictions to substrings of the context, so we keep the\n",
    "    # corresponding example_id and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cc04ddddde4bc5a2d9ef9ca8ed1d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_val_samples = 5\n",
    "eval_examples = datasets[\"validation\"]\n",
    "eval_examples = eval_examples.select(range(max_val_samples))\n",
    "# Validation Feature Creation\n",
    "eval_dataset = eval_examples.map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=eval_examples.column_names,\n",
    ")\n",
    "eval_dataset = eval_dataset.select(range(max_val_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "from transformers import default_data_collator\n",
    "# Post-processing:\n",
    "def post_processing_function(examples, features, predictions, stage=\"eval\"):\n",
    "    # Post-processing: we match the start logits and end logits to answers in the original context.\n",
    "    predictions = postprocess_qa_predictions(\n",
    "        examples=examples,\n",
    "        features=features,\n",
    "        predictions=predictions,\n",
    "        version_2_with_negative=True,\n",
    "        n_best_size=20,\n",
    "        output_dir= args.output_dir,\n",
    "        is_world_process_zero=trainer.is_world_process_zero(),\n",
    "        prefix=stage,\n",
    "    )\n",
    "    # Format the result to the format the metric expects.\n",
    "    if data_args.version_2_with_negative:\n",
    "        formatted_predictions = [\n",
    "            {\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in predictions.items()\n",
    "        ]\n",
    "    else:\n",
    "        formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in predictions.items()]\n",
    "\n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": ex[answer_column_name]} for ex in examples]\n",
    "    return EvalPrediction(predictions=formatted_predictions, label_ids=references)\n",
    "\n",
    "metric = load_metric(\"squad_v2\")\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    return metric.compute(predictions=p.predictions, references=p.label_ids)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"/storage/model/{}\".format(dir_name),\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_steps = 600,\n",
    "    eval_steps = 600,\n",
    "    evaluation_strategy ='steps',\n",
    "    gradient_accumulation_steps=8,\n",
    ")\n",
    "\n",
    "data_collator = default_data_collator\n",
    "# Initialize our Trainer\n",
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=None,\n",
    "    eval_dataset=eval_dataset,\n",
    "    eval_examples=eval_examples,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    post_process_function=post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=(array([[ 0.29639626, -0.19052106, -0.14259498, ..., -0.01155315,\n",
      "        -0.08366723, -0.01481768],\n",
      "       [ 0.31257775, -0.19946326, -0.17865051, ..., -0.01227567,\n",
      "        -0.08553155, -0.01394852],\n",
      "       [ 0.28143826, -0.08415209, -0.17613828, ...,  0.00710314,\n",
      "         0.07939225,  0.15744318],\n",
      "       [ 0.33973658, -0.14365591, -0.13565393, ...,  0.0176722 ,\n",
      "         0.08093535,  0.15494439],\n",
      "       [ 0.21687655,  0.00149453,  0.0142847 , ...,  0.07469986,\n",
      "         0.11017358, -0.03355378]], dtype=float32), array([[ 0.31722212, -0.13645889, -0.30525348, ..., -0.10378334,\n",
      "        -0.01210706, -0.09618693],\n",
      "       [ 0.36015397, -0.11562704, -0.24179308, ..., -0.10620338,\n",
      "        -0.01404711, -0.10251527],\n",
      "       [ 0.3092828 , -0.40024787,  0.2899801 , ..., -0.03269556,\n",
      "         0.12991701,  0.17861865],\n",
      "       [ 0.32766947,  0.04766992, -0.24245638, ..., -0.03881184,\n",
      "         0.12683079,  0.17482923],\n",
      "       [ 0.3389666 , -0.18650755, -0.4001005 , ..., -0.03157654,\n",
      "        -0.04213353,  0.02356099]], dtype=float32)), label_ids=None, metrics={})\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'postprocess_qa_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/trainer_qa.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, eval_examples, ignore_keys)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_process_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0meval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-35f4a4cafe15>\u001b[0m in \u001b[0;36mpost_processing_function\u001b[0;34m(examples, features, predictions, stage)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpost_processing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Post-processing: we match the start logits and end logits to answers in the original context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     predictions = postprocess_qa_predictions(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mexamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'postprocess_qa_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gzip import GzipFile\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "def read_annotation_gzip(gzipped_input_file):\n",
    "  \"\"\"Read annotation from one split of file.\"\"\"\n",
    "  if isinstance(gzipped_input_file, str):\n",
    "    gzipped_input_file = open(gzipped_input_file, 'rb')\n",
    "  annotation_dict = defaultdict(list)\n",
    "  with GzipFile(fileobj=gzipped_input_file) as input_file:\n",
    "    for line in input_file:\n",
    "      ex = _parse_example(line)\n",
    "      for key in ex:\n",
    "        annotation_dict[key].append(ex[key])\n",
    "\n",
    "  return annotation_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'document', 'question', 'annotations'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data import prepare_validation_features\n",
    "samples = validation_samples.map(prepare_validation_features, batched=True, remove_columns=eval_examples.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'name': 'mary', 'age': 24}\n"
     ]
    }
   ],
   "source": [
    "print(validation_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import six\n",
    "\n",
    "def _parse_example(line):\n",
    "    if six.PY2:\n",
    "        import HTMLParser as html_parser  # pylint:disable=g-import-not-at-top\n",
    "\n",
    "        html_unescape = html_parser.HTMLParser().unescape\n",
    "    else:\n",
    "        import html  # pylint:disable=g-import-not-at-top\n",
    "\n",
    "    html_unescape = html.unescape\n",
    "    \"\"\"Parse a single json line and emit an example dict.\"\"\"\n",
    "    ex_json = json.loads(line)\n",
    "    html_bytes = ex_json[\"document_html\"].encode(\"utf-8\")\n",
    "\n",
    "    def _parse_short_answer(short_ans):\n",
    "        \"\"\"\"Extract text of short answer.\"\"\"\n",
    "        ans_bytes = html_bytes[short_ans[\"start_byte\"] : short_ans[\"end_byte\"]]\n",
    "        # Remove non-breaking spaces.\n",
    "        ans_bytes = ans_bytes.replace(b\"\\xc2\\xa0\", b\" \")\n",
    "        text = ans_bytes.decode(\"utf-8\")\n",
    "        # Remove HTML markup.\n",
    "        text = re.sub(\"<([^>]*)>\", \"\", html_unescape(text))\n",
    "        # Replace \\xa0 characters with spaces.\n",
    "        return {\n",
    "            \"start_token\": short_ans[\"start_token\"],\n",
    "            \"end_token\": short_ans[\"end_token\"],\n",
    "            \"start_byte\": short_ans[\"start_byte\"],\n",
    "            \"end_byte\": short_ans[\"end_byte\"],\n",
    "            \"text\": text,\n",
    "        }\n",
    "\n",
    "    def _parse_annotation(an_json):\n",
    "        return {\n",
    "            # Convert to str since some IDs cannot be represented by datasets.Value('int64').\n",
    "            \"id\": str(an_json[\"annotation_id\"]),\n",
    "            \"long_answer\": {\n",
    "                \"start_token\": an_json[\"long_answer\"][\"start_token\"],\n",
    "                \"end_token\": an_json[\"long_answer\"][\"end_token\"],\n",
    "                \"start_byte\": an_json[\"long_answer\"][\"start_byte\"],\n",
    "                \"end_byte\": an_json[\"long_answer\"][\"end_byte\"],\n",
    "            },\n",
    "            \"short_answers\": [_parse_short_answer(ans) for ans in an_json[\"short_answers\"]],\n",
    "            \"yes_no_answer\": an_json[\"yes_no_answer\"] #(-1 if an_json[\"yes_no_answer\"] == \"NONE\" else an_json[\"yes_no_answer\"]),\n",
    "        }\n",
    "\n",
    "    beam.metrics.Metrics.counter(\"nq\", \"examples\").inc()\n",
    "    # Convert to str since some IDs cannot be represented by datasets.Value('int64').\n",
    "    id_ = str(ex_json[\"example_id\"])\n",
    "    return{\n",
    "                    \"id\": id_,\n",
    "                    \"document\": {\n",
    "                        \"title\": ex_json[\"document_title\"],\n",
    "                        \"url\": ex_json[\"document_url\"],\n",
    "                        \"html\": ex_json[\"document_html\"],\n",
    "                        \"tokens\": [\n",
    "                            {\"token\": t[\"token\"], \"is_html\": t[\"html_token\"]} for t in ex_json[\"document_tokens\"]\n",
    "                        ],\n",
    "                    },\n",
    "                    \"question\": {\"text\": ex_json[\"question_text\"], \"tokens\": ex_json[\"question_tokens\"]},\n",
    "                    \"annotations\": [_parse_annotation(an_json) for an_json in ex_json[\"annotations\"]],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_nq_tokens(simplified_nq_example, i):\n",
    "    '''Returns list of blank separated tokens.'''\n",
    "\n",
    "    if \"context\" not in simplified_nq_example:\n",
    "        raise ValueError(\"`get_nq_tokens` should be called on a simplified NQ\"\n",
    "                     \"example that contains the `document_text` field.\")\n",
    "\n",
    "    return simplified_nq_example[\"context\"][i].split(\" \")\n",
    "\n",
    "\n",
    "def simplify_nq_example(nq_example):\n",
    "  r\"\"\"Returns dictionary with blank separated tokens in `document_text` field.\n",
    "  Removes byte offsets from annotations, and removes `document_html` and\n",
    "  `document_tokens` fields. All annotations in the ouput are represented as\n",
    "  [start_token, end_token) offsets into the blank separated tokens in the\n",
    "  `document_text` field.\n",
    "  WARNING: Tokens are separated by a single blank character. Do not split on\n",
    "    arbitrary whitespace since different implementations have different\n",
    "    treatments of some unicode characters such as \\u180e.\n",
    "  Args:\n",
    "    nq_example: Dictionary containing original NQ example fields.\n",
    "  Returns:\n",
    "    Dictionary containing `document_text` field, not containing\n",
    "    `document_tokens` or `document_html`, and with all annotations represented\n",
    "    as [`start_token`, `end_token`) offsets into the space separated sequence.\n",
    "  \"\"\"\n",
    "\n",
    "  def _clean_token(token):\n",
    "    \"\"\"Returns token in which blanks are replaced with underscores.\n",
    "    HTML table cell openers may contain blanks if they span multiple columns.\n",
    "    There are also a very few unicode characters that are prepended with blanks.\n",
    "    Args:\n",
    "      token: Dictionary representation of token in original NQ format.\n",
    "    Returns:\n",
    "      String token.\n",
    "    \"\"\"\n",
    "    return re.sub(u\" \", \"_\", token)\n",
    "\n",
    "  tokens = [[_clean_token(t) for t in example['tokens']['token']] for example in nq_example['document']]\n",
    "  text = [\" \".join(t) for t in tokens]\n",
    "  #text = \" \".join([_clean_token(t) for t in nq_example[\"document_tokens\"]])\n",
    "\n",
    "  def _remove_html_byte_add_char_offsets(span, tokens):\n",
    "    if \"start_byte\" in span:\n",
    "      del span[\"start_byte\"]\n",
    "\n",
    "    if \"end_byte\" in span:\n",
    "      del span[\"end_byte\"]\n",
    "\n",
    "    start_tok = span[\"start_token\"]\n",
    "    end_tok = span[\"end_token\"]\n",
    "\n",
    "    chars = [len(s) for s in tokens]\n",
    "\n",
    "\n",
    "    if not isinstance(start_tok,list):\n",
    "        init , end = -1, -1\n",
    "        if start_tok != -1:\n",
    "            init = sum(chars[:start_tok])+ start_tok\n",
    "            end = init + sum(chars[start_tok:end_tok])+ end_tok - start_tok-1\n",
    "        span['start_char']=init\n",
    "        span['end_char']=end\n",
    "        '''\n",
    "        init, end =[],[]\n",
    "        for i in range(len(start_tok)):\n",
    "            s = sum(chars[:start_tok[i]])+ start_tok[i]\n",
    "            init.append(s)\n",
    "            end.append(s + sum(chars[start_tok[i]:end_tok[i]])+ end_tok[i] - start_tok[i]-1)\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "    return span\n",
    "\n",
    "  def _clean_annotation(annotation, tokens):\n",
    "    for i,(la, t) in enumerate(zip(annotation, tokens)):\n",
    "        annotation[i][\"long_answer\"]=_remove_html_byte_add_char_offsets(la[\"long_answer\"][0], t)\n",
    "        del annotation[i][\"short_answers\"]\n",
    "    '''\n",
    "    annotation[\"long_answer\"] = [\n",
    "        _remove_html_byte_add_char_offsets(la[\"long_answer\"][0], t) for (la, t) in zip(annotation, tokens)\n",
    "    ]\n",
    "    annotation[\"short_answers\"] = [\n",
    "        _remove_html_byte_add_char_offsets(sa, tokens) for sa in annotation[\"short_answers\"]\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    return annotation\n",
    "\n",
    "\n",
    "  simplified_nq_example = {\n",
    "      \"question\": [example[\"text\"] for example in nq_example[\"question\"]],\n",
    "      \"id\": nq_example[\"id\"],\n",
    "      #\"document_url\": [example[\"url\"] for example in nq_example[\"document\"]],\n",
    "      \"context\": text,\n",
    "      \"annotations\": _clean_annotation(nq_example[\"annotations\"], tokens)\n",
    "  }\n",
    "\n",
    "  for i in range(len(nq_example['document'])):\n",
    "    if len(get_nq_tokens(simplified_nq_example, i)) != len(\n",
    "        nq_example['document'][i]['tokens']['token']):\n",
    "      raise ValueError(\"Incorrect number of tokens.\")\n",
    "\n",
    "  return simplified_nq_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
